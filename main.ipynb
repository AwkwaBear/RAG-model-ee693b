{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.2.16 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.12 which is incompatible.\n",
      "langchain 0.2.16 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.12 which is incompatible.\n",
      "langchain-text-splitters 0.2.4 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.12 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: beautifulsoup4 in /home/awkwabear/anaconda3/envs/ragmodel/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/awkwabear/anaconda3/envs/ragmodel/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install langchain langchain-community langchain-chroma -c conda-forge\n",
    "%pip install -qU langchain-openai\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the following steps before setting up to get API Keys\n",
    "- Create a Langsmith account here\n",
    "  - (https://smith.langchain.com/)\n",
    "- Create an API key on OpenAIs website here\n",
    "  - (https://openai.com/index/openai-api/)\n",
    "- Follow the following link for setting up the environment and testing a hello world application\n",
    "  - (https://python.langchain.com/docs/tutorials/rag/)\n",
    "\n",
    "## Setting up api keys:\n",
    "  - Create a file called `set_api_keys.py`\n",
    "  - Paste in the following template\n",
    "---\n",
    "```\n",
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['OPENAI_API_KEY'] = '<INSERT OPEN AI API KEY>'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"<INSERT LANGCHAIN ENDPOINT>\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"<INSERT LANGCHAIN API KEY>\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"<INSERT LANGCHAIN PROJECT>\"\n",
    "```\n",
    "---\n",
    "- Replace key values to set all the API keys appropriately from accounts\n",
    "\n",
    "\n",
    "#### The following cell will run the `set_api_keys.py` file to set your API keys as environment variables that can then be accessed to interface with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run set_api_keys.py\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Scientific Discovery Agent, like ChemCrow, is a domain-specific tool that combines a large language model (LLM) with expert-designed tools to facilitate tasks in areas such as organic synthesis, drug discovery, and materials design. It utilizes a structured workflow that incorporates reasoning and actions based on user prompts, following a format known as ReAct. This agent is designed to assist in scientific inquiries while considering the associated risks of misuse, particularly concerning sensitive applications.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is a Scientific Discovery Agent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
